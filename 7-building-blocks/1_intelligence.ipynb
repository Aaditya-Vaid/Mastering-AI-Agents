{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0945ae35",
   "metadata": {},
   "source": [
    "# Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01652408",
   "metadata": {},
   "source": [
    "Intelligence: The \"brain\" that processes information and makes decisions using LLMs.\n",
    "This component handles context understanding, instruction following, and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f587e",
   "metadata": {},
   "source": [
    "# Groq API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158d669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the coordinates of Paris. I'm not exactly sure where Paris is located in terms of latitude and longitude. I think Paris is the capital of France, right? So, France is in Europe, but I'm not certain about the exact position. I remember that Paris is known as the \"City of Light\" and is famous for landmarks like the Eiffel Tower, the Louvre, and Notre-Dame. \n",
      "\n",
      "I think the Eiffel Tower is a significant landmark, so maybe its coordinates can help. Wait, but the user asked for Paris, not the Eiffel Tower specifically. So, I should focus on the city itself. I'm not a geography expert, but I think Paris is somewhere in the northern part of France. I recall that France is in Western Europe, bordered by countries like Germany, Belgium, and Spain.\n",
      "\n",
      "I'm trying to remember if I've seen any maps of France. Paris is in the north, near the Seine River. I think the Seine flows through the city. Now, about the coordinates. Latitude and longitude are measured in degrees, minutes, and seconds. Latitude ranges from 0° at the equator to 90° at the poles, and longitude from 0° at Greenwich, England, going east and west.\n",
      "\n",
      "I'm not sure about the exact numbers, but I think Paris is somewhere around 48° latitude. Maybe 48°51' N? That sounds familiar. For longitude, since Paris is in France and France is in Western Europe, I believe it's in the Eastern Hemisphere, so the longitude would be east. I think Paris is around 2°21' E. \n",
      "\n",
      "Wait, but sometimes I get confused between east and west. Greenwich, England is at 0°, so Paris is to the east of that. So, yes, east longitude. I think that's correct. So putting it together, the coordinates would be approximately 48°51' N and 2°21' E. \n",
      "\n",
      "I should double-check if those numbers make sense. I know that London is around 51°30' N and 0°7' W, so Paris being a bit south and to the east makes sense. Also, I think the Eiffel Tower is at 48°51' N, 2°21' E, so that lines up with Paris's coordinates. \n",
      "\n",
      "I'm pretty confident now that the coordinates of Paris are 48°51′ N latitude and 2°21′ E longitude. I don't think I'm missing anything here. It's a major city, so these coordinates are likely well-documented and commonly known.\n",
      "</think>\n",
      "\n",
      "The coordinates of Paris are approximately 48°51′ N latitude and 2°21′ E longitude.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'chat completion returns:\\n    id: string\\n    choices: list,\\n    and many more things.\\n\\n    The most important is choices[0].message.content\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = Groq(\n",
    "    api_key = os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer in a professional manner and do not include any think tags and it's content in the answer.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the coordinates of paris?\"\n",
    "        }\n",
    "    ],\n",
    "    model = \"deepseek-r1-distill-llama-70b\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n",
    "'''chat completion returns:\n",
    "    id: string\n",
    "    choices: list,\n",
    "    and many more things.\n",
    "    \n",
    "    The most important is choices[0].message.content\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ea99b",
   "metadata": {},
   "source": [
    "# Groq API with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e4561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message approach:\n",
      "I'm not aware of the current date as my knowledge cutoff is December 2023, and I do not have real-time access to information. However, I can suggest checking a reliable online source, such as a calendar or news website, to find out the current date.\n",
      "chain approach:\n",
      "I'm not aware of the current date as my knowledge cutoff is December 2023, and I do not have real-time access to information. However, I can suggest checking a reliable online source, such as a calendar or news website, to find out the current date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model= \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    api_key = os.environ.get(\"GROQ_API_KEY\"),\n",
    "    temperature=0.0\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Give answer like a professional. If you don't know the answer just say you don't know.\"),\n",
    "    (\"user\", \"What is today date?\")\n",
    "])\n",
    "\n",
    "# Format the prompt template into actual messages\n",
    "messages = prompt.format_messages()\n",
    "# or use chain approach like this\n",
    "chain = prompt | llm\n",
    "\n",
    "chat_completion = llm.invoke(messages)\n",
    "chain_output = chain.invoke({})\n",
    "print(f\"message approach:\\n{chat_completion.content}\")\n",
    "print(f\"chain approach:\\n{chain_output.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cdc558",
   "metadata": {},
   "source": [
    "# Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16687b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic programming (DP) is a powerful algorithmic technique used to solve complex problems by breaking them down into simpler, overlapping subproblems.  It's an optimization technique, primarily used when brute-force approaches would be computationally expensive (e.g., exponential time).\n",
      "\n",
      "Here's a breakdown of the key concepts and characteristics of dynamic programming:\n",
      "\n",
      "**Core Principles:**\n",
      "\n",
      "1. **Optimal Substructure:** The optimal solution to the overall problem can be constructed from the optimal solutions to its subproblems.  This means that if you can find the best way to solve the smaller parts, you can combine those best parts to find the best solution for the whole.\n",
      "\n",
      "2. **Overlapping Subproblems:** The same subproblems are solved multiple times during the process of breaking down the main problem. DP exploits this by solving each subproblem only once and storing its solution. When the subproblem is encountered again, the stored solution is simply retrieved, avoiding redundant computation.\n",
      "\n",
      "**How it Works:**\n",
      "\n",
      "The general process of dynamic programming involves these steps:\n",
      "\n",
      "1. **Identify Subproblems:**  Divide the original problem into smaller, manageable subproblems.  These subproblems often relate to each other in a recursive fashion.\n",
      "\n",
      "2. **Define the Recursive Relation (or Recurrence Relation):**  This is the heart of DP.  It defines how to calculate the solution to a subproblem based on the solutions to its smaller subproblems.  This relation describes the optimal substructure.\n",
      "\n",
      "3. **Choose a Storage Method:** Decide how to store the solutions to the subproblems.  Common methods include:\n",
      "    *   **Memoization (Top-Down Approach):** This is a form of recursion with caching.  You write a recursive function that solves the problem.  Before computing the result for a subproblem, you check if it's already been solved (stored in a lookup table, typically an array or hash map). If it is, you return the stored result.  If not, you compute it, store it, and then return it.\n",
      "    *   **Tabulation (Bottom-Up Approach):** You build a table (usually an array or multi-dimensional array) to store the solutions to the subproblems.  You start with the base cases (the simplest subproblems, which are usually known solutions) and iteratively compute the solutions to larger subproblems, using the previously computed solutions from the table.\n",
      "\n",
      "4. **Solve the Problem:** Based on your chosen method (memoization or tabulation), you implement the recursive relation to build the solution, either by recursively exploring subproblems and caching the results (memoization), or by iteratively filling in the table (tabulation).\n",
      "\n",
      "**Common Applications and Examples:**\n",
      "\n",
      "Dynamic programming is used in a wide variety of applications, including:\n",
      "\n",
      "*   **Optimization Problems:** Finding the shortest path, the knapsack problem (selecting items to maximize value within a weight limit), making change with the fewest coins.\n",
      "*   **Sequence Alignment:** In bioinformatics, aligning DNA or protein sequences.\n",
      "*   **Computer Graphics:**  Generating optimal paths for image rendering.\n",
      "*   **Game Theory:** Finding optimal strategies in games.\n",
      "*   **Operations Research:** Solving resource allocation problems.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "*   **Fibonacci Sequence:**\n",
      "    *   **Subproblems:** Calculating F(0), F(1), F(2), ... F(n)\n",
      "    *   **Recursive Relation:** F(n) = F(n-1) + F(n-2)\n",
      "    *   **Memoization:**\n",
      "        ```python\n",
      "        def fib_memo(n, memo={}):\n",
      "            if n in memo:\n",
      "                return memo[n]\n",
      "            if n <= 1:\n",
      "                return n\n",
      "            result = fib_memo(n-1, memo) + fib_memo(n-2, memo)\n",
      "            memo[n] = result\n",
      "            return result\n",
      "        ```\n",
      "    *   **Tabulation:**\n",
      "        ```python\n",
      "        def fib_tab(n):\n",
      "            dp = [0] * (n + 1)\n",
      "            dp[0] = 0\n",
      "            if n > 0:\n",
      "                dp[1] = 1\n",
      "            for i in range(2, n + 1):\n",
      "                dp[i] = dp[i-1] + dp[i-2]\n",
      "            return dp[n]\n",
      "        ```\n",
      "\n",
      "*   **Longest Common Subsequence (LCS):** Finding the longest sequence of characters that are present in the same order in two given strings.\n",
      "    *   **Subproblems:** Finding the LCS of prefixes of the two strings.\n",
      "    *   **Recursive Relation:** (Consider strings `X` and `Y` with lengths `m` and `n` respectively)\n",
      "        *   `LCS(X[1...i], Y[1...j]) = LCS(X[1...i-1], Y[1...j-1]) + 1` if `X[i] == Y[j]`\n",
      "        *   `LCS(X[1...i], Y[1...j]) = max(LCS(X[1...i-1], Y[1...j]), LCS(X[1...i], Y[1...j-1]))` if `X[i] != Y[j]`\n",
      "    *   **Tabulation** (usually): A 2D table is used to store the lengths of the LCS for all prefix pairs.\n",
      "\n",
      "**Benefits of Dynamic Programming:**\n",
      "\n",
      "*   **Efficiency:** Significantly reduces the time complexity compared to brute-force approaches, often transforming exponential time complexity to polynomial or even linear time.\n",
      "*   **Optimal Solutions:** Guarantees finding the optimal solution to problems with optimal substructure.\n",
      "*   **Well-Defined Approach:** Provides a structured framework for problem-solving.\n",
      "\n",
      "**Disadvantages of Dynamic Programming:**\n",
      "\n",
      "*   **Space Complexity:** Can require significant memory for storing the solutions to subproblems, especially for problems with large input sizes or complex subproblem structures.\n",
      "*   **Overhead:** The process of setting up the table or recursive function with memoization can introduce some overhead.\n",
      "*   **Not Always Applicable:** Requires the problem to have optimal substructure and overlapping subproblems.  Not all problems are suited for this technique.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "Dynamic programming is a powerful algorithmic technique that optimizes problem-solving by breaking down complex problems into overlapping subproblems, solving each subproblem only once, and storing the results for future use. It's an invaluable tool for solving a wide range of optimization and decision-making problems.  Mastering the concepts of optimal substructure, overlapping subproblems, recursive relations, and memoization/tabulation is essential for successfully applying dynamic programming.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Using Google AI API with loaded environment variables\n",
    "client = genai.Client(\n",
    "    api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    vertexai=False\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    contents=\"What is dynamic programming?\"\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c535d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. These machines are designed to perform tasks that typically require human intelligence, such as:\n",
      "\n",
      "*   **Learning:** Acquiring information and rules for using the information.\n",
      "*   **Reasoning:** Using rules to reach approximate or definite conclusions.\n",
      "*   **Problem-solving:** Using rules to reach specific goals.\n",
      "*   **Perception:** Using sensors to perceive the world.\n",
      "*   **Natural language processing:** Understanding and generating human language.\n",
      "\n",
      "AI systems are often categorized based on their capabilities and how they are implemented. Some common types of AI include:\n",
      "\n",
      "*   **Narrow or Weak AI:** Designed to perform a specific task. This is the most common type of AI today (e.g., virtual assistants, recommendation systems).\n",
      "*   **General or Strong AI:** Possesses human-level intelligence and can perform any intellectual task that a human being can. This type of AI does not yet exist.\n",
      "*   **Super AI:** Surpasses human intelligence and capabilities. This is a hypothetical concept.\n",
      "\n",
      "AI is a rapidly evolving field with applications across various industries, including healthcare, finance, transportation, and entertainment.\n",
      "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and act like humans. These machines are designed to perform tasks that typically require human intelligence, such as:\n",
      "\n",
      "*   **Learning:** Acquiring information and rules for using the information.\n",
      "*   **Reasoning:** Using rules to reach approximate or definite conclusions.\n",
      "*   **Problem-solving:** Finding solutions to complex challenges.\n",
      "*   **Perception:** Interpreting sensory input, such as images and speech.\n",
      "*   **Natural language processing:** Understanding and generating human language.\n",
      "\n",
      "AI systems are often categorized based on their capabilities and how they are implemented. Some common types of AI include:\n",
      "\n",
      "*   **Narrow or Weak AI:** Designed for a specific task, such as image recognition or playing chess. This is the most common type of AI today.\n",
      "*   **General or Strong AI:** Possesses human-level intelligence and can perform any intellectual task that a human being can. This type of AI does not yet exist.\n",
      "*   **Super AI:** Surpasses human intelligence and capabilities. This is a theoretical concept.\n",
      "\n",
      "AI is implemented using various techniques, including:\n",
      "\n",
      "*   **Machine Learning:** Algorithms that allow systems to learn from data without being explicitly programmed.\n",
      "*   **Deep Learning:** A subset of machine learning that uses artificial neural networks with multiple layers to analyze data.\n",
      "*   **Natural Language Processing (NLP):** Enables machines to understand, interpret, and generate human language.\n",
      "*   **Computer Vision:** Enables machines to \"see\" and interpret images.\n",
      "*   **Robotics:** Designing and building robots that can perform tasks automatically.\n",
      "\n",
      "AI has a wide range of applications across various industries, including healthcare, finance, transportation, and entertainment. It is rapidly evolving and has the potential to transform many aspects of our lives.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    temperature = 0,\n",
    "    api_key=os.environ.get(\"GEMINI_API_KEY\")\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Give answer like a professional. If you don't know the answer just say you don't know.\"),\n",
    "    (\"user\", \"what is artificial intelligence\")\n",
    "])\n",
    "\n",
    "messages = prompt.format_messages()\n",
    "chain = prompt | llm\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n",
    "response = chain.invoke({})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51709f68",
   "metadata": {},
   "source": [
    "# Multimodal Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8fee4",
   "metadata": {},
   "source": [
    "### Groq with Multimodal Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0922fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a mechanical component with a central silver metal piece featuring a circular hole and several smaller holes around its edge. The component is surrounded by black rubber or plastic pieces, which are attached to the metal part via bolts. \n",
      "\n",
      "The background of the image is white, suggesting that it may be a product photo or technical illustration. \n",
      "\n",
      "The object appears to be a type of mechanical assembly, possibly used in an industrial or automotive context.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "image_path = \"wheels.jpeg\"\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "chat = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"what is in this image?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    ")\n",
    "\n",
    "print(chat.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec2e17",
   "metadata": {},
   "source": [
    "### Gemini with Multimodal Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e0e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a Mecanum wheel. These wheels are designed to provide omnidirectional movement for robots and other vehicles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"), vertexai=False)\n",
    "\n",
    "# Load the image\n",
    "with open(\"wheels.jpeg\", 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "# Proper multimodal content structure - text first, then image\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    contents=[\n",
    "        genai.types.Part.from_text(text=\"What is in this image?\"),\n",
    "        genai.types.Part.from_bytes(data=image_bytes, mime_type='image/jpeg')\n",
    "    ]\n",
    ")\n",
    "# for chunk in response:\n",
    "#     print(chunk.text, end=\"\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a22c4b",
   "metadata": {},
   "source": [
    "#### Gemini langchain with audio input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4654c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for audio: Alone, having conversations with me in the thought\n",
      "You know, I can run away to that world\n",
      "Even if no one else can stand to hear you talk\n",
      "And I can always try\n",
      "Under your palm, or one from your daydreams of\n",
      "Me, love\n",
      "\n",
      "Outside, the world is warming while you waste\n",
      "Being in your own\n",
      "Despite, why unwilling making fun\n",
      "The thoughts you drew\n",
      "The silence, what's there between both of ours\n",
      "For still, they are yours\n",
      "\n",
      "You made me\n",
      "You made me\n",
      "All that I am and all that you need me to be\n",
      "We're stolen from your\n",
      "Own string of faults and long remarks that I play for\n",
      "Why can't you just shut up and act normal\n",
      "Then maybe you could fix us\n",
      "It's you and me in every scene in your ghost town\n",
      "All that I am and all that you need me to be\n",
      "We're stolen from your\n",
      "Own string of faults and long remarks that I play for\n",
      "Why can't you just shut up and act normal\n",
      "Then maybe you could fix us\n",
      "It's you and me in every scene at the end of us\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Ensure you have an audio file named 'example_audio.mp3' or provide the correct path.\n",
    "audio_file_path = \"Celina Fang x Danté - Consious (LYRICS).mp3\"\n",
    "audio_mime_type = \"audio/mpeg\"\n",
    "\n",
    "\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    encoded_audio = base64.b64encode(audio_file.read()).decode(\"utf-8\")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Transcribe the audio.\"},\n",
    "        {\n",
    "            \"type\": \"media\",\n",
    "            \"data\": encoded_audio,  # Use base64 string directly\n",
    "            \"mime_type\": audio_mime_type,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response = llm.invoke([message])  # Uncomment to run\n",
    "print(f\"Response for audio: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c26e10",
   "metadata": {},
   "source": [
    "#### Gemini langchain with video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c68089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for video: Here are the lyrics extracted from the video:\n",
      "\n",
      "(Intro)\n",
      "Celina Fang\n",
      "Danté\n",
      "Conscious\n",
      "Lyrics Video\n",
      "\n",
      "(Verse 1)\n",
      "Alone\n",
      "Having conversations with me\n",
      "In the dark\n",
      "You know\n",
      "I can't run away\n",
      "No matter who you are\n",
      "Even if no one else\n",
      "Can stand to hear you talk\n",
      "\n",
      "(Chorus)\n",
      "I'm like an animal\n",
      "Trapped under your palm\n",
      "Born from your daydreams\n",
      "Of being loved\n",
      "\n",
      "(Verse 2)\n",
      "Outside the weather's warming\n",
      "While you waste me in your room\n",
      "Despise my unwilling\n",
      "Making from the thoughts you drew\n",
      "The silence haunts the air\n",
      "Both of our lungs\n",
      "Forced to be your illusion\n",
      "\n",
      "(Chorus)\n",
      "I'm like an animal\n",
      "Trapped under your palm\n",
      "Born from your daydreams\n",
      "Of being loved\n",
      "\n",
      "(Bridge)\n",
      "You made me\n",
      "All that I am and all\n",
      "All that you were stolen\n",
      "From your own string\n",
      "Of faults and wrong remarks\n",
      "That I pay for\n",
      "Why can't you just shut up\n",
      "And act normal\n",
      "You could fix how\n",
      "It's you and me\n",
      "In every scene\n",
      "In your ghost town\n",
      "\n",
      "(Chorus)\n",
      "I'm like an animal\n",
      "Trapped under your palm\n",
      "Born from your daydreams\n",
      "Of being loved\n",
      "\n",
      "(Outro)\n",
      "All that I am and all\n",
      "All that you need me\n",
      "Were stolen from your own string\n",
      "Of faults and wrong remarks\n",
      "That I pay for\n",
      "Why can't you just shut up\n",
      "And act normal\n",
      "You could fix how\n",
      "It's you and me\n",
      "In every scene\n",
      "In your ghost town\n",
      "Yet I know that I am\n",
      "You and you are me\n",
      "Find out\n",
      "Even you will\n",
      "From your own\n",
      "Scream\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Ensure you have a video file named 'example_video.mp4' or provide the correct path.\n",
    "video_file_path = \"videoplayback.mp4\"\n",
    "video_mime_type = \"video/mp4\"\n",
    "\n",
    "\n",
    "with open(video_file_path, \"rb\") as video_file:\n",
    "    encoded_video = base64.b64encode(video_file.read()).decode(\"utf-8\")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"Extract text from the video and represent it in a form of song lyrics\"},\n",
    "        {\n",
    "            \"type\": \"media\",\n",
    "            \"data\": encoded_video,  # Use base64 string directly\n",
    "            \"mime_type\": video_mime_type,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response = llm.invoke([message])  # Uncomment to run\n",
    "print(f\"Response for video: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3213a",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
